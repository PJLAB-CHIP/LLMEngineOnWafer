chiplet:
  __target__: chiplet.Chiplet
  num_x: 5
  num_y: 4
  die_num: 20
  dies:
  - __target__: die.Die
    num_x: 5
    num_y: 4
    tile_num: 256
    d2d_bw: 4500
    dram:
      __target__: dram.Dram
      bandwidth: 900
      latency: 0.1
      memory_size: 1600
      memory_used: 0
    tiles:
    - __target__: components.tile.Tile
      num_x: 16
      num_y: 16
      sram: 1.25
      bandwidth: 9000
      tflops: 1.02
      tops: 0.0625
      hop_latency: 0.01
cluster:
  power_budget: 232000
  servers:
  - sku: dgx-a100
    count: 40
  - sku: dgx-h100
    count: 0
  interconnects:
  - link: infiniband
    topology: p2p
router:
  overheads:
    routing_delay: 0
  _target_: router.NoOpRouter
arbiter:
  _target_: arbiter.NoOpArbiter
  overheads: {}
hardware_repo:
  processors: configs/hardware_repo/processors
  skus: configs/hardware_repo/skus
  interconnects: configs/hardware_repo/interconnects
model_repo:
  architectures: configs/model_repo/architectures
  sizes: configs/model_repo/sizes
orchestrator_repo:
  allocators: configs/orchestrator_repo/allocators
  schedulers: configs/orchestrator_repo/schedulers
performance_model:
  _target_: performance_model.DatabasePerformanceModel
  db_path: data/perf_model.csv
power_model:
  _target_: power_model.ConstantPowerModel
  idle_power:
    a100-80gb: 63
    h100-80gb: 75
  prompt_power:
    a100-80gb: 400
    h100-80gb: 700
  token_power:
    a100-80gb: 250
    h100-80gb: 380
applications:
- application_id: 0
  model_architecture: llama2-70b
  model_size: llama2-70b-fp16
  allocator: noop
  scheduler: kv_jsq
  overheads: {}
  debug: ${debug}
  _target_: application.Application
trace:
  dir: traces/
  filename: AzureLLMInferenceTrace_conv
  path: ${trace.dir}/${trace.filename}.csv
start_state:
  state_type: splitwise_${start_state.prompt.num_instances}_${start_state.token.num_instances}
  application_id: 0
  split_type: homogeneous
  prompt:
    instance_type: Splitwise
    max_batch_size: 512
    max_batch_tokens: 2048
    max_preemptions: 4
    pipeline_parallelism: 2
    tensor_parallelism: 1024
    num_instances: 4
    instance_names:
    - dgx-a100
  token:
    instance_type: Splitwise
    max_batch_size: 512
    max_batch_tokens: 2048
    max_preemptions: 4
    pipeline_parallelism: 1
    tensor_parallelism: 32
    num_instances: 32
    instance_names:
    - dgx-a100
end_time: 86400
debug: true
seed: 0
choices: ${hydra:runtime.choices}
output_dir: req_results/${seed}/${start_state.state_type}/${trace.filename}/${cluster.servers.0.count}_${cluster.servers.1.count}/${applications.0.model_architecture}/${applications.0.scheduler}
