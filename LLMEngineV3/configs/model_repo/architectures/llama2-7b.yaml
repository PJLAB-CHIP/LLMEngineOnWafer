_target_: model.LLMArchitecture
name: llama2-7b
num_layers: 32
hidden_size: 4096
num_heads: 32
