_target_: model.LLMArchitecture
name: llama2-70b
num_layers: 80
hidden_size: 8192
num_heads: 64
