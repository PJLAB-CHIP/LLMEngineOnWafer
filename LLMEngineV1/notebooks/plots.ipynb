{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "import glob\n",
    "import math\n",
    "import os\n",
    "\n",
    "from pathlib import Path\n",
    "from importlib import reload\n",
    "\n",
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.colors as mcolors\n",
    "import seaborn as sns\n",
    "import scipy.stats as stats\n",
    "\n",
    "from plotly.subplots import make_subplots\n",
    "\n",
    "from perf_model import PerfModel\n",
    "from utils import *\n",
    "\n",
    "# set the max columns to none\n",
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_dir = \"../results\"\n",
    "plots_dir = \"../plots\"\n",
    "perf_model_path = \"../data/perf_model.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model_to_plot = \"llama2-70b\"\n",
    "model_to_plot = \"bloom-176b\"\n",
    "#seed = 9\n",
    "seed = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "perf_model = PerfModel(perf_model_path, init=True)\n",
    "normalize_model = model_to_plot\n",
    "normalize_hardware = \"a100-80gb\"\n",
    "normalize_tp = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# isopower\n",
    "print(\"Num servers in cluster\")\n",
    "\n",
    "print(\"isopower\")\n",
    "max_h100 = 40\n",
    "for num_h100 in range(0, max_h100+1, 5):\n",
    "    num_a100 = int(44 * (max_h100 - num_h100) // 24.8)\n",
    "    print(num_a100, num_h100, num_a100+num_h100)\n",
    "\n",
    "# isocost\n",
    "print(\"isocost\")\n",
    "max_h100 = 40\n",
    "for num_h100 in range(0, max_h100+1, 5):\n",
    "    num_a100 = int(4.76 * (max_h100 - num_h100) // 2.21)\n",
    "    print(num_a100, num_h100, num_a100+num_h100)\n",
    "\n",
    "print(\"isopower hhcap\")\n",
    "max_h100 = 40\n",
    "for prompt_h100 in range(0, max_h100+1, 5):\n",
    "    token_h100 = int(44 * (max_h100 - prompt_h100) // 30.8)\n",
    "    print(prompt_h100, token_h100, prompt_h100+token_h100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(configs, traces, seed, quantiles=[0.5, 0.9, 0.99], model=\"\"):\n",
    "    results = []\n",
    "    request_dfs = {}\n",
    "    for trace in traces:\n",
    "        for config in configs:\n",
    "            name = config[\"name\"]\n",
    "            scheduler = config[\"scheduler\"]\n",
    "            start_state = config[\"start_state\"]\n",
    "            cluster = config[\"cluster\"]\n",
    "\n",
    "            summary_df = get_summary_data(results_dir, scheduler, start_state, cluster, trace, seed, model=model)\n",
    "            request_df = get_request_data(results_dir, scheduler, start_state, cluster, trace, seed, model=model)\n",
    "            if summary_df is None or request_df is None:\n",
    "                continue\n",
    "\n",
    "            perf_model.add_baseline_perf(request_df, normalize_model, normalize_hardware, normalize_tp)\n",
    "            request_df[\"baseline_e2e\"] = request_df[\"baseline_ttft\"] + request_df[\"baseline_tbt\"] * (request_df[\"token_sizes\"] - 1)\n",
    "            request_df[\"ttft_slowdown\"] = request_df[\"ttft_times\"] / request_df[\"baseline_ttft\"]\n",
    "            request_df[\"tbt_slowdown\"] = request_df[\"tbt_times\"] / request_df[\"baseline_tbt\"]\n",
    "            request_df[\"e2e_slowdown\"] = request_df[\"response_times\"] / request_df[\"baseline_e2e\"]\n",
    "\n",
    "            # check if OOM by existence of oom.csv\n",
    "            oom = False\n",
    "            if os.path.exists(f\"{results_dir}/{seed}/{start_state}/{trace}/{cluster}/{model}/{scheduler}/oom.csv\"):\n",
    "                oom = True\n",
    "\n",
    "            result = {}\n",
    "            for key, value in config.items():\n",
    "                result[key] = value\n",
    "            result[\"trace\"] = trace\n",
    "            result[\"seed\"] = seed\n",
    "            for quantile in quantiles:\n",
    "                result[f\"ttft_slowdown_p{int(quantile * 100)}\"] = request_df[\"ttft_slowdown\"].quantile(quantile)\n",
    "                result[f\"tbt_slowdown_p{int(quantile * 100)}\"] = request_df[\"tbt_slowdown\"].quantile(quantile)\n",
    "                result[f\"e2e_slowdown_p{int(quantile * 100)}\"] = request_df[\"e2e_slowdown\"].quantile(quantile)\n",
    "            for quantile in quantiles:\n",
    "                result[f\"ttft_times_p{int(quantile * 100)}\"] = summary_df[f\"ttft_times_p{int(quantile * 100)}\"][0]\n",
    "                result[f\"tbt_times_p{int(quantile * 100)}\"] = summary_df[f\"tbt_times_p{int(quantile * 100)}\"][0]\n",
    "                result[f\"e2e_times_p{int(quantile * 100)}\"] = summary_df[f\"response_times_p{int(quantile * 100)}\"][0]\n",
    "            result[\"oom\"] = oom\n",
    "\n",
    "            # save results to later create a dataframe\n",
    "            results.append(result)\n",
    "            request_dfs[f\"{name}_{trace}\"] = request_df\n",
    "\n",
    "    results_df = pd.DataFrame(results)\n",
    "    return results_df, request_dfs\n",
    "\n",
    "def get_slo(y_var, quantile):\n",
    "    if y_var == \"tbt_slowdown\" or y_var == \"e2e_slowdown\":\n",
    "        if quantile == 0.5:\n",
    "            return 1.25\n",
    "        if quantile == 0.9:\n",
    "            return 1.5\n",
    "        if quantile == 0.99:\n",
    "            return 5\n",
    "    elif y_var == \"ttft_slowdown\":\n",
    "        if quantile == 0.5:\n",
    "            return 2\n",
    "        if quantile == 0.9:\n",
    "            return 3\n",
    "        if quantile == 0.99:\n",
    "            return 6\n",
    "    else:\n",
    "        raise Exception(f\"Invalid y_var:quantile {y_var}:{quantile}\")\n",
    "\n",
    "def get_y_limits(y_var, quantile):\n",
    "    if quantile == 0.5 or quantile == 0.9:\n",
    "        return {\n",
    "            'bottom': 0,\n",
    "            'top': 4\n",
    "        }\n",
    "    elif quantile == 0.99:\n",
    "        return {\n",
    "            'bottom': 0,\n",
    "            'top': 8\n",
    "        }\n",
    "    raise Exception(f\"Invalid y_var:quantile {y_var}:{quantile}\")   \n",
    "\n",
    "def plot_y_vs_trace_new(results_df,\n",
    "                        traces,\n",
    "                        y_vars=[\"ttft_times\", \"tbt_times\", \"e2e_times\"],\n",
    "                        y_vars_labels=[\"TTFT\", \"TBT\", \"E2E\"],\n",
    "                        quantiles=[0.5, 0.9, 0.99],\n",
    "                        title=None):\n",
    "    fig, axs = plt.subplots(nrows=len(y_vars),\n",
    "                            ncols=len(quantiles),\n",
    "                            figsize=(len(quantiles) * 2.5, len(y_vars) * 1.5),\n",
    "                            sharex=True,\n",
    "                            constrained_layout=True)\n",
    "\n",
    "    # plot\n",
    "    for y_var in y_vars:\n",
    "        for quantile in quantiles:\n",
    "            sns.lineplot(data=results_df,\n",
    "                         x=\"trace\",\n",
    "                         y=f\"{y_var}_p{int(quantile * 100)}\",\n",
    "                         hue=\"name\",\n",
    "                         style=\"name\",\n",
    "                         markers=True,\n",
    "                         markersize=7,\n",
    "                         ax=axs[y_vars.index(y_var)][quantiles.index(quantile)])\n",
    "\n",
    "    for ax in axs.flatten():\n",
    "        ax.grid()\n",
    "        ax.get_legend().set_visible(False)\n",
    "        ax.set_xlabel(\"Request Rate (req/s)\")\n",
    "        xlabels = [trace.split(\"_\")[2] for trace in traces]\n",
    "        ax.set_xticks(ticks=range(0, len(traces)), labels=xlabels)\n",
    "\n",
    "    # create a single legend in center of figure\n",
    "    handles, labels = axs[0][0].get_legend_handles_labels()\n",
    "    fig.legend(handles, labels, loc='lower center', ncol=3, title=\"\", bbox_to_anchor=(0.5, 1.01))\n",
    "\n",
    "    #axs[0][0].set_yscale(\"log\")\n",
    "    #axs[0][1].set_yscale(\"log\")\n",
    "    #axs[2][0].set_yscale(\"log\")\n",
    "    #axs[2][1].set_yscale(\"log\")\n",
    "\n",
    "    for y_var in y_vars:\n",
    "        for quantile in quantiles:\n",
    "            axs[y_vars.index(y_var)][quantiles.index(quantile)].set_ylabel(\n",
    "                f\"Normalized\\np{int(quantile*100)} {y_vars_labels[y_vars.index(y_var)]}\")\n",
    "            #axs[y_vars.index(y_var)][quantiles.index(quantile)].set_ylabel(f\"p{int(quantile*100)} {y_var} (s)\")\n",
    "            y_limits = get_y_limits(y_var, quantile)\n",
    "            axs[y_vars.index(y_var)][quantiles.index(quantile)].set_ylim(**y_limits)\n",
    "            slo = get_slo(y_var, quantile)\n",
    "            # add SLO lines\n",
    "            axs[y_vars.index(y_var)][quantiles.index(quantile)].axhline(y=slo, color=\"red\", linestyle=\"--\")\n",
    "\n",
    "    if title:\n",
    "        fig.suptitle(title)\n",
    "\n",
    "    plt.margins(x=0)\n",
    "    # set 300dpi\n",
    "    plt.gcf().set_dpi(300)\n",
    "\n",
    "\n",
    "def plot_y_vs_trace_new_swapped(results_df,\n",
    "                                traces,\n",
    "                                y_vars=[\"ttft_times\", \"tbt_times\", \"e2e_times\"],\n",
    "                                y_vars_labels=[\"TTFT\", \"TBT\", \"E2E\"],\n",
    "                                quantiles=[0.5, 0.9, 0.99],\n",
    "                                title=None):\n",
    "    fig, axs = plt.subplots(nrows=len(quantiles),\n",
    "                            ncols=len(y_vars),\n",
    "                            figsize=(len(y_vars) * 2.5, len(quantiles) * 1.5),\n",
    "                            sharex=True,\n",
    "                            constrained_layout=True)\n",
    "\n",
    "    axs = np.array(axs).reshape(len(quantiles), len(y_vars))\n",
    "\n",
    "    # plot\n",
    "    for y_var in y_vars:\n",
    "        for quantile in quantiles:\n",
    "            sns.lineplot(data=results_df,\n",
    "                         x=\"trace\",\n",
    "                         y=f\"{y_var}_p{int(quantile * 100)}\",\n",
    "                         hue=\"name\",\n",
    "                         style=\"name\",\n",
    "                         markers=True,\n",
    "                         markersize=7,\n",
    "                         ax=axs[quantiles.index(quantile)][y_vars.index(y_var)])\n",
    "\n",
    "    for ax in axs.flatten():\n",
    "        ax.grid()\n",
    "        ax.get_legend().set_visible(False)\n",
    "        ax.set_xlabel(\"Request Rate (req/s)\")\n",
    "        xlabels = [trace.split(\"_\")[2] for trace in traces]\n",
    "        ax.set_xticks(ticks=range(0, len(traces)), labels=xlabels)\n",
    "\n",
    "    # create a single legend in center of figure\n",
    "    handles, labels = axs[0][0].get_legend_handles_labels()\n",
    "    fig.legend(handles, labels, loc='lower center', ncol=3, title=\"\", bbox_to_anchor=(0.5, 1.01))\n",
    "\n",
    "    #axs[0][0].set_yscale(\"log\")\n",
    "    #axs[0][1].set_yscale(\"log\")\n",
    "    #axs[2][0].set_yscale(\"log\")\n",
    "    #axs[2][1].set_yscale(\"log\")\n",
    "\n",
    "    for y_var in y_vars:\n",
    "        for quantile in quantiles:\n",
    "            axs[quantiles.index(quantile)][y_vars.index(y_var)].set_ylabel(\n",
    "                f\"Normalized\\np{int(quantile*100)} {y_vars_labels[y_vars.index(y_var)]}\")\n",
    "            #axs[y_vars.index(y_var)][quantiles.index(quantile)].set_ylabel(f\"p{int(quantile*100)} {y_var} (s)\")\n",
    "            y_limits = get_y_limits(y_var, quantile)\n",
    "            axs[quantiles.index(quantile)][y_vars.index(y_var)].set_ylim(**y_limits)\n",
    "            slo = get_slo(y_var, quantile)\n",
    "            # add SLO lines\n",
    "            axs[quantiles.index(quantile)][y_vars.index(y_var)].axhline(y=slo, color=\"red\", linestyle=\"--\")\n",
    "\n",
    "    fig.subplots_adjust(left=0)\n",
    "    if title:\n",
    "        fig.suptitle(title)\n",
    "\n",
    "    # set 300dpi\n",
    "    plt.gcf().set_dpi(300)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "slos = {\n",
    "    \"ttft_slowdown_p99\": get_slo(\"ttft_slowdown\", 0.99),\n",
    "    \"tbt_slowdown_p99\": get_slo(\"tbt_slowdown\", 0.99),\n",
    "    \"e2e_slowdown_p99\": get_slo(\"e2e_slowdown\", 0.99),\n",
    "    \"ttft_slowdown_p90\": get_slo(\"ttft_slowdown\", 0.9),\n",
    "    \"tbt_slowdown_p90\": get_slo(\"tbt_slowdown\", 0.9),\n",
    "    \"e2e_slowdown_p90\": get_slo(\"e2e_slowdown\", 0.9),\n",
    "    \"ttft_slowdown_p50\": get_slo(\"ttft_slowdown\", 0.5),\n",
    "    \"tbt_slowdown_p50\": get_slo(\"tbt_slowdown\", 0.5),\n",
    "    \"e2e_slowdown_p50\": get_slo(\"e2e_slowdown\", 0.5),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_cost_power_optimal_within_slo(results_df, baseline_system, slos):\n",
    "    \"\"\"\n",
    "    plot grouped bar chart of cost and power for each system,\n",
    "    normalized to baseline_system\n",
    "    \"\"\"\n",
    "    # find configs within SLO\n",
    "    configs_within_slo = find_within_slo(results_df, slos)\n",
    "\n",
    "    # find cheapest configs\n",
    "    cheapest_configs = find_cheapest(configs_within_slo)\n",
    "\n",
    "    # find least power configs\n",
    "    least_power_configs = find_least_power(configs_within_slo)\n",
    "\n",
    "    # normalize cost and power to baseline_system\n",
    "    baseline_cost = cheapest_configs[cheapest_configs[\"system\"] == baseline_system][\"cost\"].values[0]\n",
    "    baseline_power = least_power_configs[least_power_configs[\"system\"] == baseline_system][\"power\"].values[0]\n",
    "    cheapest_configs[\"cost\"] /= baseline_cost\n",
    "    least_power_configs[\"power\"] /= baseline_power\n",
    "\n",
    "    # reshape the dataframes for seaborn\n",
    "    cheapest_configs_melted = cheapest_configs.melt(id_vars='system', value_vars='cost', \n",
    "                            var_name='variable', \n",
    "                            value_name='value')\n",
    "    least_power_configs_melted = least_power_configs.melt(id_vars='system', value_vars='power', \n",
    "                            var_name='variable', \n",
    "                            value_name='value')\n",
    "    combined_df = pd.concat([cheapest_configs_melted, least_power_configs_melted])\n",
    "\n",
    "    # rename cost and power to cheapest and least power\n",
    "    combined_df[\"variable\"] = combined_df[\"variable\"].replace(\"cost\", \"Cost\")\n",
    "    combined_df[\"variable\"] = combined_df[\"variable\"].replace(\"power\", \"Power\")\n",
    "\n",
    "    # plot\n",
    "    fig, ax = plt.subplots(1, 1, figsize=(4, 3), constrained_layout=True)\n",
    "    # order baseline_system first\n",
    "    sns.barplot(data=combined_df, x='system', y='value', hue='variable', palette='dark', ax=ax)\n",
    "                #order=[baseline_system, \"Baseline-A100\", \"Splitwise-AA\", \"Splitwise-HA\", \"Splitwise-HH\", \"Splitwise-HHcap\"])\n",
    "    #sns.barplot(data=combined_df, x='system', y='value', hue='variable', palette='dark')\n",
    "    ax.legend(loc=\"lower center\", bbox_to_anchor=(0.5, 1.01), ncol=3, title=\"\")\n",
    "    xticklabels = results_df[\"system\"].unique()\n",
    "    # add a \\n between the name and the number of servers\n",
    "    #xticklabels = [f\"{xticklabel.split('(')[0]}\\n({xticklabel.split('(')[1]}\" for xticklabel in xticklabels]\n",
    "    # rotate and set xticks\n",
    "    ax.set_xticks(ticks=range(0, len(results_df[\"system\"].unique())), labels=xticklabels, rotation=90)\n",
    "    # set minor ticks on y-axis\n",
    "    ax.set_ylabel(\"Normalized Value\")\n",
    "    ax.set_xlabel(\"\")\n",
    "    ax.grid(axis='y')\n",
    "    ax.minorticks_on()\n",
    "    ax.set_axisbelow(True)\n",
    "    # make minor ticks increment every 0.25\n",
    "    ax.yaxis.set_minor_locator(plt.MultipleLocator(0.25))\n",
    "    ax.grid(which='minor', linestyle=':', linewidth='0.5', color='black', axis='y')\n",
    "    return combined_df\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_isothroughput_cost_optimal_within_slo(results_df, baseline_system, slos):\n",
    "    \"\"\"\n",
    "    plot grouped bar chart of cost and power for each system,\n",
    "    normalized to baseline_system\n",
    "    \"\"\"\n",
    "    # find configs within SLO\n",
    "    configs_within_slo = find_within_slo(results_df, slos)\n",
    "\n",
    "    # find cheapest configs\n",
    "    cheapest_configs = find_cheapest(configs_within_slo)\n",
    "    \n",
    "    # pick unique config for each system\n",
    "    cheapest_configs = cheapest_configs.drop_duplicates(subset=[\"system\"])\n",
    "\n",
    "    # normalize cost and power to baseline_system\n",
    "    baseline_servers = cheapest_configs[cheapest_configs[\"system\"] == baseline_system][\"num_servers\"].values[0]\n",
    "    baseline_cost = cheapest_configs[cheapest_configs[\"system\"] == baseline_system][\"cost\"].values[0]\n",
    "    baseline_power = cheapest_configs[cheapest_configs[\"system\"] == baseline_system][\"power\"].values[0]\n",
    "    cheapest_configs[\"num_servers\"] /= baseline_servers\n",
    "    cheapest_configs[\"cost\"] /= baseline_cost\n",
    "    cheapest_configs[\"power\"] /= baseline_power\n",
    "\n",
    "    # reshape the dataframes for seaborn\n",
    "    num_servers_melted = cheapest_configs.melt(id_vars='system', value_vars='num_servers', \n",
    "                            var_name='variable', \n",
    "                            value_name='value')\n",
    "    cheapest_melted = cheapest_configs.melt(id_vars='system', value_vars='cost', \n",
    "                            var_name='variable', \n",
    "                            value_name='value')\n",
    "    power_melted = cheapest_configs.melt(id_vars='system', value_vars='power', \n",
    "                            var_name='variable', \n",
    "                            value_name='value')\n",
    "    combined_df = pd.concat([num_servers_melted, cheapest_melted, power_melted])\n",
    "\n",
    "    # rename cost and power to cheapest and least power\n",
    "    combined_df[\"variable\"] = combined_df[\"variable\"].replace(\"num_servers\", \"#Servers\")\n",
    "    combined_df[\"variable\"] = combined_df[\"variable\"].replace(\"cost\", \"Cost\")\n",
    "    combined_df[\"variable\"] = combined_df[\"variable\"].replace(\"power\", \"Power\")\n",
    "\n",
    "    # plot\n",
    "    fig, ax = plt.subplots(1, 1, figsize=(4, 3), constrained_layout=True)\n",
    "    # order baseline_system first\n",
    "    sns.barplot(data=combined_df, x='system', y='value', hue='variable', palette='dark', ax=ax)\n",
    "                #order=[baseline_system, \"Baseline-A100\", \"Splitwise-AA\", \"Splitwise-HA\", \"Splitwise-HH\", \"Splitwise-HHcap\"])\n",
    "    #sns.barplot(data=combined_df, x='system', y='value', hue='variable', palette='dark')\n",
    "    ax.legend(loc=\"lower center\", bbox_to_anchor=(0.5, 1.01), ncol=3, title=\"\")\n",
    "    xticklabels = cheapest_configs[\"name\"].unique()\n",
    "    # add a \\n between the name and the number of servers\n",
    "    xticklabels = [f\"{xticklabel.split('(')[0]}\\n({xticklabel.split('(')[1]}\" for xticklabel in xticklabels]\n",
    "    # add a \\n between the name and the number of servers\n",
    "    #xticklabels = [f\"{xticklabel.split('(')[0]}\\n({xticklabel.split('(')[1]}\" for xticklabel in xticklabels]\n",
    "    # rotate and set xticks\n",
    "    ax.set_xticks(ticks=range(0, len(results_df[\"system\"].unique())), labels=xticklabels, rotation=90)\n",
    "    # set minor ticks on y-axis\n",
    "    ax.set_ylabel(\"Normalized Value\")\n",
    "    ax.set_xlabel(\"\")\n",
    "    ax.grid(axis='y')\n",
    "    ax.minorticks_on()\n",
    "    ax.set_axisbelow(True)\n",
    "    # make minor ticks increment every 0.25\n",
    "    ax.yaxis.set_minor_locator(plt.MultipleLocator(0.25))\n",
    "    ax.grid(which='minor', linestyle=':', linewidth='0.5', color='black', axis='y')\n",
    "    return combined_df\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_isothroughput_power_optimal_within_slo(results_df, baseline_system, slos):\n",
    "    \"\"\"\n",
    "    plot grouped bar chart of cost and power for each system,\n",
    "    normalized to baseline_system\n",
    "    \"\"\"\n",
    "    # find configs within SLO\n",
    "    configs_within_slo = find_within_slo(results_df, slos)\n",
    "\n",
    "    # find cheapest configs\n",
    "    cheapest_configs = find_least_power(configs_within_slo)\n",
    "    \n",
    "    # pick unique config for each system\n",
    "    cheapest_configs = cheapest_configs.drop_duplicates(subset=[\"system\"])\n",
    "\n",
    "    # normalize cost and power to baseline_system\n",
    "    baseline_servers = cheapest_configs[cheapest_configs[\"system\"] == baseline_system][\"num_servers\"].values[0]\n",
    "    baseline_cost = cheapest_configs[cheapest_configs[\"system\"] == baseline_system][\"cost\"].values[0]\n",
    "    baseline_power = cheapest_configs[cheapest_configs[\"system\"] == baseline_system][\"power\"].values[0]\n",
    "    cheapest_configs[\"num_servers\"] /= baseline_servers\n",
    "    cheapest_configs[\"cost\"] /= baseline_cost\n",
    "    cheapest_configs[\"power\"] /= baseline_power\n",
    "\n",
    "    # reshape the dataframes for seaborn\n",
    "    num_servers_melted = cheapest_configs.melt(id_vars='system', value_vars='num_servers', \n",
    "                            var_name='variable', \n",
    "                            value_name='value')\n",
    "    cheapest_melted = cheapest_configs.melt(id_vars='system', value_vars='cost', \n",
    "                            var_name='variable', \n",
    "                            value_name='value')\n",
    "    power_melted = cheapest_configs.melt(id_vars='system', value_vars='power', \n",
    "                            var_name='variable', \n",
    "                            value_name='value')\n",
    "    combined_df = pd.concat([num_servers_melted, cheapest_melted, power_melted])\n",
    "\n",
    "    # rename cost and power to cheapest and least power\n",
    "    combined_df[\"variable\"] = combined_df[\"variable\"].replace(\"num_servers\", \"#Servers\")\n",
    "    combined_df[\"variable\"] = combined_df[\"variable\"].replace(\"cost\", \"Cost\")\n",
    "    combined_df[\"variable\"] = combined_df[\"variable\"].replace(\"power\", \"Power\")\n",
    "\n",
    "    # plot\n",
    "    fig, ax = plt.subplots(1, 1, figsize=(4, 3), constrained_layout=True)\n",
    "    # order baseline_system first\n",
    "    sns.barplot(data=combined_df, x='system', y='value', hue='variable', palette='dark', ax=ax)\n",
    "                #order=[baseline_system, \"Baseline-A100\", \"Splitwise-AA\", \"Splitwise-HA\", \"Splitwise-HH\", \"Splitwise-HHcap\"])\n",
    "    #sns.barplot(data=combined_df, x='system', y='value', hue='variable', palette='dark')\n",
    "    ax.legend(loc=\"lower center\", bbox_to_anchor=(0.5, 1.01), ncol=3, title=\"\")\n",
    "    xticklabels = cheapest_configs[\"name\"].unique()\n",
    "    # add a \\n between the name and the number of servers\n",
    "    xticklabels = [f\"{xticklabel.split('(')[0]}\\n({xticklabel.split('(')[1]}\" for xticklabel in xticklabels]\n",
    "    # add a \\n between the name and the number of servers\n",
    "    #xticklabels = [f\"{xticklabel.split('(')[0]}\\n({xticklabel.split('(')[1]}\" for xticklabel in xticklabels]\n",
    "    # rotate and set xticks\n",
    "    ax.set_xticks(ticks=range(0, len(results_df[\"system\"].unique())), labels=xticklabels, rotation=90)\n",
    "    # set minor ticks on y-axis\n",
    "    ax.set_ylabel(\"Normalized Value\")\n",
    "    ax.set_xlabel(\"\")\n",
    "    ax.grid(axis='y')\n",
    "    ax.minorticks_on()\n",
    "    ax.set_axisbelow(True)\n",
    "    # make minor ticks increment every 0.25\n",
    "    ax.yaxis.set_minor_locator(plt.MultipleLocator(0.25))\n",
    "    ax.grid(which='minor', linestyle=':', linewidth='0.5', color='black', axis='y')\n",
    "    return combined_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_isothroughput_count_optimal_within_slo(results_df, baseline_system, slos):\n",
    "    \"\"\"\n",
    "    plot grouped bar chart of cost and power for each system,\n",
    "    normalized to baseline_system\n",
    "    \"\"\"\n",
    "    # find configs within SLO\n",
    "    configs_within_slo = find_within_slo(results_df, slos)\n",
    "\n",
    "    # find cheapest configs\n",
    "    cheapest_configs = find_least_count(configs_within_slo)\n",
    "\n",
    "    # pick unique config for each system\n",
    "    cheapest_configs = cheapest_configs.drop_duplicates(subset=[\"system\"])\n",
    "\n",
    "    # normalize cost and power to baseline_system\n",
    "    baseline_servers = cheapest_configs[cheapest_configs[\"system\"] == baseline_system][\"num_servers\"].values[0]\n",
    "    baseline_cost = cheapest_configs[cheapest_configs[\"system\"] == baseline_system][\"cost\"].values[0]\n",
    "    baseline_power = cheapest_configs[cheapest_configs[\"system\"] == baseline_system][\"power\"].values[0]\n",
    "    cheapest_configs[\"num_servers\"] /= baseline_servers\n",
    "    cheapest_configs[\"cost\"] /= baseline_cost\n",
    "    cheapest_configs[\"power\"] /= baseline_power\n",
    "\n",
    "    # reshape the dataframes for seaborn\n",
    "    num_servers_melted = cheapest_configs.melt(id_vars='system', value_vars='num_servers', \n",
    "                            var_name='variable', \n",
    "                            value_name='value')\n",
    "    cheapest_melted = cheapest_configs.melt(id_vars='system', value_vars='cost', \n",
    "                            var_name='variable', \n",
    "                            value_name='value')\n",
    "    power_melted = cheapest_configs.melt(id_vars='system', value_vars='power', \n",
    "                            var_name='variable', \n",
    "                            value_name='value')\n",
    "    combined_df = pd.concat([num_servers_melted, cheapest_melted, power_melted])\n",
    "\n",
    "    # rename cost and power to cheapest and least power\n",
    "    combined_df[\"variable\"] = combined_df[\"variable\"].replace(\"num_servers\", \"#Servers\")\n",
    "    combined_df[\"variable\"] = combined_df[\"variable\"].replace(\"cost\", \"Cost\")\n",
    "    combined_df[\"variable\"] = combined_df[\"variable\"].replace(\"power\", \"Power\")\n",
    "\n",
    "    # plot\n",
    "    fig, ax = plt.subplots(1, 1, figsize=(4, 3), constrained_layout=True)\n",
    "    # order baseline_system first\n",
    "    sns.barplot(data=combined_df, x='system', y='value', hue='variable', palette='dark', ax=ax)\n",
    "                #order=[baseline_system, \"Baseline-A100\", \"Splitwise-AA\", \"Splitwise-HA\", \"Splitwise-HH\", \"Splitwise-HHcap\"])\n",
    "    #sns.barplot(data=combined_df, x='system', y='value', hue='variable', palette='dark')\n",
    "    ax.legend(loc=\"lower center\", bbox_to_anchor=(0.5, 1.01), ncol=3, title=\"\")\n",
    "    xticklabels = cheapest_configs[\"name\"].unique()\n",
    "    # add a \\n between the name and the number of servers\n",
    "    xticklabels = [f\"{xticklabel.split('(')[0]}\\n({xticklabel.split('(')[1]}\" for xticklabel in xticklabels]\n",
    "    # add a \\n between the name and the number of servers\n",
    "    #xticklabels = [f\"{xticklabel.split('(')[0]}\\n({xticklabel.split('(')[1]}\" for xticklabel in xticklabels]\n",
    "    # rotate and set xticks\n",
    "    ax.set_xticks(ticks=range(0, len(results_df[\"system\"].unique())), labels=xticklabels, rotation=90)\n",
    "    # set minor ticks on y-axis\n",
    "    ax.set_ylabel(\"Normalized Value\")\n",
    "    ax.set_xlabel(\"\")\n",
    "    ax.grid(axis='y')\n",
    "    ax.minorticks_on()\n",
    "    ax.set_axisbelow(True)\n",
    "    # make minor ticks increment every 0.25\n",
    "    ax.yaxis.set_minor_locator(plt.MultipleLocator(0.25))\n",
    "    ax.grid(which='minor', linestyle=':', linewidth='0.5', color='black', axis='y')\n",
    "    return combined_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_cost_throughput_optimal_within_slo(results_df, baseline_system, slos):\n",
    "    \"\"\"\n",
    "    plot grouped bar chart of cost and throughput for each system,\n",
    "    normalized to baseline_system\n",
    "    \"\"\"\n",
    "    # find configs within SLO\n",
    "    configs_within_slo = find_within_slo(results_df, slos)\n",
    "\n",
    "    # find least power configs\n",
    "    max_throughput_configs = find_max_throughput(configs_within_slo)\n",
    "    #print(max_throughput_configs)\n",
    "\n",
    "    # normalize cost and throughput to baseline_system\n",
    "    baseline_servers = max_throughput_configs[max_throughput_configs[\"system\"] == baseline_system][\"num_servers\"].values[0]\n",
    "    baseline_cost = max_throughput_configs[max_throughput_configs[\"system\"] == baseline_system][\"cost\"].values[0]\n",
    "    baseline_throughput = max_throughput_configs[max_throughput_configs[\"system\"] == baseline_system][\"throughput\"].values[0]\n",
    "    max_throughput_configs[\"num_servers\"] /= baseline_servers\n",
    "    max_throughput_configs[\"cost\"] /= baseline_cost\n",
    "    max_throughput_configs[\"throughput\"] /= baseline_throughput\n",
    "\n",
    "    # reshape the dataframes for seaborn\n",
    "    max_throughput_melted = max_throughput_configs.melt(id_vars='system', value_vars='throughput', \n",
    "                            var_name='variable', \n",
    "                            value_name='value')\n",
    "    cost_melted = max_throughput_configs.melt(id_vars='system', value_vars='cost', \n",
    "                            var_name='variable', \n",
    "                            value_name='value')\n",
    "    num_servers_melted = max_throughput_configs.melt(id_vars='system', value_vars='num_servers',\n",
    "                            var_name='variable', \n",
    "                            value_name='value')\n",
    "    combined_df = pd.concat([num_servers_melted, max_throughput_melted, cost_melted])\n",
    "\n",
    "    # rename cost and throughput to cheapest and max throughput\n",
    "    combined_df[\"variable\"] = combined_df[\"variable\"].replace(\"cost\", \"Cost\")\n",
    "    combined_df[\"variable\"] = combined_df[\"variable\"].replace(\"throughput\", \"Throughput\")\n",
    "    combined_df[\"variable\"] = combined_df[\"variable\"].replace(\"num_servers\", \"#Servers\")\n",
    "\n",
    "    # plot\n",
    "    fig, ax = plt.subplots(1, 1, figsize=(4, 3), constrained_layout=True)\n",
    "    # order baseline_system first\n",
    "    sns.barplot(data=combined_df, x='system', y='value', hue='variable', palette='dark', ax=ax)\n",
    "                #order=[baseline_system, \"Baseline-A100\", \"Splitwise-AA\", \"Splitwise-HA\", \"Splitwise-HH\", \"Splitwise-HHcap\"])\n",
    "    #sns.barplot(data=combined_df, x='system', y='value', hue='variable', palette='dark')\n",
    "    ax.legend(loc=\"lower center\", bbox_to_anchor=(0.5, 1.01), ncol=3, title=\"\")\n",
    "    xticklabels = combined_df[\"name\"].unique()\n",
    "    # add a \\n between the name and the number of servers\n",
    "    xticklabels = [f\"{xticklabel.split('(')[0]}\\n({xticklabel.split('(')[1]}\" for xticklabel in xticklabels]\n",
    "    # rotate and set xticks\n",
    "    ax.set_xticks(ticks=range(0, len(results_df[\"system\"].unique())), labels=xticklabels, rotation=90)\n",
    "    # set minor ticks on y-axis\n",
    "    ax.set_ylabel(\"Normalized Value\")\n",
    "    ax.set_xlabel(\"\")\n",
    "    ax.grid(axis='y')\n",
    "    ax.minorticks_on()\n",
    "    ax.set_axisbelow(True)\n",
    "    # make minor ticks increment every 0.25\n",
    "    ax.yaxis.set_minor_locator(plt.MultipleLocator(0.25))\n",
    "    ax.grid(which='minor', linestyle=':', linewidth='0.5', color='black', axis='y')\n",
    "    return combined_df\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_power_throughput_optimal_within_slo(results_df, baseline_system, slos):\n",
    "    \"\"\"\n",
    "    plot grouped bar chart of power and throughput for each system,\n",
    "    normalized to baseline_system\n",
    "    \"\"\"\n",
    "    # find configs within SLO\n",
    "    configs_within_slo = find_within_slo(results_df, slos)\n",
    "\n",
    "    # find least power configs\n",
    "    max_throughput_configs = find_max_throughput(configs_within_slo)\n",
    "    #print(max_throughput_configs)\n",
    "\n",
    "    # normalize power and throughput to baseline_system\n",
    "    baseline_servers = max_throughput_configs[max_throughput_configs[\"system\"] == baseline_system][\"num_servers\"].values[0]\n",
    "    baseline_power = max_throughput_configs[max_throughput_configs[\"system\"] == baseline_system][\"power\"].values[0]\n",
    "    baseline_throughput = max_throughput_configs[max_throughput_configs[\"system\"] == baseline_system][\"throughput\"].values[0]\n",
    "    max_throughput_configs[\"num_servers\"] /= baseline_servers\n",
    "    max_throughput_configs[\"power\"] /= baseline_power\n",
    "    max_throughput_configs[\"throughput\"] /= baseline_throughput\n",
    "\n",
    "    # reshape the dataframes for seaborn\n",
    "    max_throughput_melted = max_throughput_configs.melt(id_vars='system', value_vars='throughput', \n",
    "                            var_name='variable', \n",
    "                            value_name='value')\n",
    "    power_melted = max_throughput_configs.melt(id_vars='system', value_vars='power', \n",
    "                            var_name='variable', \n",
    "                            value_name='value')\n",
    "    num_servers_melted = max_throughput_configs.melt(id_vars='system', value_vars='num_servers',\n",
    "                            var_name='variable', \n",
    "                            value_name='value')\n",
    "    combined_df = pd.concat([num_servers_melted, max_throughput_melted, power_melted])\n",
    "\n",
    "    # rename power and throughput to cheapest and max throughput\n",
    "    combined_df[\"variable\"] = combined_df[\"variable\"].replace(\"power\", \"Power\")\n",
    "    combined_df[\"variable\"] = combined_df[\"variable\"].replace(\"throughput\", \"Throughput\")\n",
    "    combined_df[\"variable\"] = combined_df[\"variable\"].replace(\"num_servers\", \"#Servers\")\n",
    "\n",
    "    # plot\n",
    "    fig, ax = plt.subplots(1, 1, figsize=(4, 3), constrained_layout=True)\n",
    "    # order baseline_system first\n",
    "    sns.barplot(data=combined_df, x='system', y='value', hue='variable', palette='dark', ax=ax)\n",
    "                #order=[baseline_system, \"Baseline-A100\", \"Splitwise-AA\", \"Splitwise-HA\", \"Splitwise-HH\", \"Splitwise-HHcap\"])\n",
    "    #sns.barplot(data=combined_df, x='system', y='value', hue='variable', palette='dark')\n",
    "    ax.legend(loc=\"lower center\", bbox_to_anchor=(0.5, 1.01), ncol=3, title=\"\")\n",
    "    xticklabels = results_df[\"name\"].unique()\n",
    "    # add a \\n between the name and the number of servers\n",
    "    xticklabels = [f\"{xticklabel.split('(')[0]}\\n({xticklabel.split('(')[1]}\" for xticklabel in xticklabels]\n",
    "    # rotate and set xticks\n",
    "    ax.set_xticks(ticks=range(0, len(results_df[\"system\"].unique())), labels=xticklabels, rotation=90)\n",
    "    ax.set_ylabel(\"Normalized Value\")\n",
    "    ax.set_xlabel(\"\")\n",
    "    ax.grid(axis='y')\n",
    "    ax.minorticks_on()\n",
    "    ax.set_axisbelow(True)\n",
    "    # make minor ticks increment every 0.25\n",
    "    ax.yaxis.set_minor_locator(plt.MultipleLocator(0.25))\n",
    "    ax.grid(which='minor', linestyle=':', linewidth='0.5', color='black', axis='y')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# isopower clusters, conv trace\n",
    "\n",
    "isopower_conv_configs = [\n",
    "    baseline_a100_config(70),\n",
    "    baseline_h100_config(40),\n",
    "    splitwise_aa_config(45, 25),\n",
    "    splitwise_hh_config(25, 15),\n",
    "    splitwise_ha_config(25, 26),\n",
    "    splitwise_hhcap_config(25, 21),\n",
    "]\n",
    "\n",
    "min_x = 50\n",
    "max_x = 181\n",
    "if model_to_plot == \"bloom-176b\":\n",
    "    min_x = 30\n",
    "    max_x = 161\n",
    "isopower_conv_traces = [f\"rr_conv_{i}_1min\" for i in range(80, 151, 10)]\n",
    "isopower_conv_traces = [f\"rr_conv_{i}\" for i in range(min_x, max_x, 10)]\n",
    "\n",
    "isopower_conv_results_df, isopower_conv_request_dfs = get_data(\n",
    "    isopower_conv_configs, isopower_conv_traces, seed=seed, model=model_to_plot)\n",
    "plot_y_vs_trace_new(isopower_conv_results_df,\n",
    "                    isopower_conv_traces,\n",
    "                    y_vars=[\"ttft_slowdown\", \"tbt_slowdown\", \"e2e_slowdown\"],\n",
    "                    #y_vars_labels=[\"TTFT\\nSlowdown\", \"TBT\\nSlowdown\", \"E2E\\nSlowdown\"],\n",
    "                    title=\"\")\n",
    "                    #title=\"Isopower Clusters, Conversation Trace\")\n",
    "axs = plt.gca()\n",
    "axs.set_xticks(ticks=range(0, len(isopower_conv_traces), 2), labels=[f\"{i}\" for i in range(min_x, max_x, 20)])\n",
    "#plt.subplots_adjust(left=0.)\n",
    "isopower_conv_results_df.to_csv(f\"{plotsdata_dir}/isopower_conv_{model_to_plot}.csv\", index=False)\n",
    "plt.savefig(f\"{plots_dir}/isopower_conv_{model_to_plot}.pdf\", bbox_inches='tight')\n",
    "plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# isopower clusters, code trace\n",
    "\n",
    "isopower_code_configs = [\n",
    "    baseline_a100_config(70),\n",
    "    baseline_h100_config(40),\n",
    "    splitwise_aa_config(55, 15),\n",
    "    splitwise_hh_config(35, 5),\n",
    "    splitwise_ha_config(35, 8),\n",
    "    splitwise_hhcap_config(35, 7),\n",
    "]\n",
    "\n",
    "min_x = 50\n",
    "max_x = 181\n",
    "if model_to_plot == \"bloom-176b\":\n",
    "    min_x = 30\n",
    "    max_x = 101\n",
    "isopower_code_traces = [f\"rr_code_{i}_1min\" for i in range(50, 121, 10)]\n",
    "isopower_code_traces = [f\"rr_code_{i}\" for i in range(min_x, max_x, 10)]\n",
    "\n",
    "isopower_code_results_df, isopower_code_request_dfs = get_data(\n",
    "    isopower_code_configs, isopower_code_traces, seed=seed, model=model_to_plot)\n",
    "plot_y_vs_trace_new(isopower_code_results_df,\n",
    "                    isopower_code_traces,\n",
    "                    y_vars=[\"ttft_slowdown\", \"tbt_slowdown\", \"e2e_slowdown\"],\n",
    "                    #y_vars_labels=[\"TTFT\\nSlowdown\", \"TBT\\nSlowdown\", \"E2E\\nSlowdown\"],\n",
    "                    title=\"\")\n",
    "                    #title=\"Isopower Clusters, Code Trace\")\n",
    "isopower_code_results_df.to_csv(f\"{plotsdata_dir}/isopower_code_{model_to_plot}.csv\", index=False)\n",
    "plt.savefig(f\"{plots_dir}/isopower_code_{model_to_plot}.pdf\", bbox_inches='tight')\n",
    "plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# code cluster for conv trace\n",
    "\n",
    "isopower_code_for_conv_results_df, isopower_code_for_conv_request_dfs = \\\n",
    "    get_data(isopower_code_configs, isopower_conv_traces, seed=seed, model=model_to_plot)\n",
    "plot_y_vs_trace_new_swapped(isopower_code_for_conv_results_df,\n",
    "                    isopower_conv_traces,\n",
    "                    y_vars=[\"ttft_slowdown\", \"tbt_slowdown\", \"e2e_slowdown\"],\n",
    "                    quantiles=[0.9],\n",
    "                    #y_vars_labels=[\"TTFT\\nSlowdown\", \"TBT\\nSlowdown\", \"E2E\\nSlowdown\"],\n",
    "                    title=\"\")\n",
    "axs = plt.gca()\n",
    "min_x = 50\n",
    "max_x = 181\n",
    "if model_to_plot == \"bloom-176b\":\n",
    "    min_x = 30 \n",
    "    max_x = 161\n",
    "axs.set_xticks(ticks=range(0, len(isopower_conv_traces), 2), labels=[f\"{i}\" for i in range(30, max_x, 20)])\n",
    "#plt.savefig(f\"{plots_dir}/isopower_code_for_conv_{model_to_plot}.pdf\", bbox_inches='tight')\n",
    "isopower_code_for_conv_results_df.to_csv(f\"{plotsdata_dir}/isopower_code_for_conv_{model_to_plot}_p90.csv\", index=False)\n",
    "plt.savefig(f\"{plots_dir}/isopower_code_for_conv_{model_to_plot}_p90.pdf\", bbox_inches='tight')\n",
    "plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "find_max_throughput(find_within_slo(isopower_code_for_conv_results_df, slos))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "find_max_throughput(find_within_slo(isopower_conv_results_df, slos))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# conv cluster for code trace\n",
    "\n",
    "isopower_conv_for_code_results_df, isopower_conv_for_code_request_dfs = \\\n",
    "    get_data(isopower_conv_configs, isopower_code_traces, seed=seed, model=model_to_plot)\n",
    "plot_y_vs_trace_new(isopower_conv_for_code_results_df,\n",
    "                    isopower_code_traces,\n",
    "                    y_vars=[\"ttft_slowdown\", \"tbt_slowdown\", \"e2e_slowdown\"],\n",
    "                    y_vars_labels=[\"TTFT\\nSlowdown\", \"TBT\\nSlowdown\", \"E2E\\nSlowdown\"],\n",
    "                    title=\"Isopower Conversation Cluster, Code Trace\")\n",
    "max_x = 181\n",
    "if model_to_plot == \"bloom-176b\":\n",
    "    max_x = 141\n",
    "isopower_conv_for_code_results_df.to_csv(f\"{plotsdata_dir}/isopower_conv_for_code_{model_to_plot}.csv\", index=False)\n",
    "plt.savefig(f\"{plots_dir}/isopower_conv_for_code_{model_to_plot}.pdf\", bbox_inches='tight')\n",
    "#axs.set_xticks(ticks=range(0, len(isopower_code_traces), 2), labels=[f\"{i}\" for i in range(50, max_x, 20)])\n",
    "plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "find_max_throughput(find_within_slo(isopower_code_results_df, slos))[[\"name\", \"trace\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "find_max_throughput(find_within_slo(isopower_conv_for_code_results_df, slos))[[\"name\", \"trace\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# isocost clusters, conv trace\n",
    "\n",
    "isocost_conv_configs = [\n",
    "    baseline_a100_config(86),\n",
    "    baseline_h100_config(40),\n",
    "    splitwise_aa_config(51, 35),\n",
    "    splitwise_hh_config(25, 15),\n",
    "    splitwise_ha_config(30, 21),\n",
    "    splitwise_hhcap_config(30, 10),\n",
    "]\n",
    "\n",
    "max_x = 181\n",
    "if model_to_plot == \"bloom-176b\":\n",
    "    max_x = 171\n",
    "isocost_conv_traces = [f\"rr_conv_{i}_1min\" for i in range(80, 151, 10)]\n",
    "isocost_conv_traces = [f\"rr_conv_{i}\" for i in range(50, max_x, 10)]\n",
    "\n",
    "isocost_conv_results_df, isocost_conv_request_dfs = get_data(\n",
    "    isocost_conv_configs, isocost_conv_traces, seed=seed, model=model_to_plot)\n",
    "plt.close()\n",
    "plot_y_vs_trace_new(isocost_conv_results_df,\n",
    "                    isocost_conv_traces,\n",
    "                    y_vars=[\"ttft_slowdown\", \"tbt_slowdown\", \"e2e_slowdown\"],\n",
    "                    y_vars_labels=[\"TTFT\\nSlowdown\", \"TBT\\nSlowdown\", \"E2E\\nSlowdown\"],\n",
    "                    title=\"Isocost Clusters, Conversation Trace\")\n",
    "axs = plt.gca()\n",
    "axs.set_xticks(ticks=range(0, len(isocost_conv_traces), 2), labels=[f\"{i}\" for i in range(50, max_x, 20)])\n",
    "isocost_conv_results_df.to_csv(f\"{plotsdata_dir}/isocost_conv_{model_to_plot}.csv\", index=False)\n",
    "plt.savefig(f\"{plots_dir}/isocost_conv_{model_to_plot}.pdf\", bbox_inches='tight')\n",
    "plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# isocost clusters, code trace\n",
    "\n",
    "isocost_code_configs = [\n",
    "    baseline_a100_config(86),\n",
    "    baseline_h100_config(40),\n",
    "    splitwise_aa_config(66, 20),\n",
    "    splitwise_hh_config(35, 5),\n",
    "    splitwise_ha_config(35, 10),\n",
    "    splitwise_hhcap_config(35, 7),\n",
    "]\n",
    "\n",
    "max_x = 181\n",
    "if model_to_plot == \"bloom-176b\":\n",
    "    max_x = 121\n",
    "isocost_code_traces = [f\"rr_code_{i}_1min\" for i in range(50, 121, 10)]\n",
    "isocost_code_traces = [f\"rr_code_{i}\" for i in range(50, max_x, 10)]\n",
    "\n",
    "isocost_code_results_df, isocost_code_request_dfs = get_data(\n",
    "    isocost_code_configs, isocost_code_traces, seed=seed, model=model_to_plot)\n",
    "plot_y_vs_trace_new(isocost_code_results_df,\n",
    "                    isocost_code_traces,\n",
    "                    y_vars=[\"ttft_slowdown\", \"tbt_slowdown\", \"e2e_slowdown\"],\n",
    "                    y_vars_labels=[\"TTFT\\nSlowdown\", \"TBT\\nSlowdown\", \"E2E\\nSlowdown\"],\n",
    "                    title=\"Isocost Clusters, Code Trace\")\n",
    "isocost_code_results_df.to_csv(f\"{plotsdata_dir}/isocost_code_{model_to_plot}.csv\", index=False)\n",
    "plt.savefig(f\"{plots_dir}/isocost_code_{model_to_plot}.pdf\", bbox_inches='tight')\n",
    "plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cost and max.throughput for isopower configurations\n",
    "\n",
    "plot_cost_throughput_optimal_within_slo(isopower_conv_results_df, \"Baseline-A100\", slos)\n",
    "isopower_conv_results_df.to_csv(f\"{plotsdata_dir}/isopower_conv_cost_throughput_{model_to_plot}.csv\", index=False)\n",
    "plt.savefig(f\"{plots_dir}/isopower_conv_cost_throughput_{model_to_plot}.pdf\", bbox_inches='tight')\n",
    "plt.show()\n",
    "plt.close()\n",
    "\n",
    "plot_cost_throughput_optimal_within_slo(isopower_code_results_df, \"Baseline-A100\", slos)\n",
    "isopower_code_results_df.to_csv(f\"{plotsdata_dir}/isopower_code_cost_throughput_{model_to_plot}.csv\", index=False)\n",
    "plt.savefig(f\"{plots_dir}/isopower_code_cost_throughput_{model_to_plot}.pdf\", bbox_inches='tight')\n",
    "plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# power and max. throughput for isopower configurations\n",
    "\n",
    "plot_power_throughput_optimal_within_slo(isocost_conv_results_df, \"Baseline-A100\", slos)\n",
    "isocost_conv_results_df.to_csv(f\"{plotsdata_dir}/isocost_conv_power_throughput_{model_to_plot}.csv\", index=False)\n",
    "plt.savefig(f\"{plots_dir}/isocost_conv_power_throughput_{model_to_plot}.pdf\", bbox_inches='tight')\n",
    "plt.show()\n",
    "plt.close()\n",
    "\n",
    "plot_power_throughput_optimal_within_slo(isocost_code_results_df, \"Baseline-A100\", slos)\n",
    "isocost_code_results_df.to_csv(f\"{plotsdata_dir}/isocost_code_power_throughput_{model_to_plot}.csv\", index=False)\n",
    "plt.savefig(f\"{plots_dir}/isocost_code_power_throughput_{model_to_plot}.pdf\", bbox_inches='tight')\n",
    "plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# provisioning sweep\n",
    "\n",
    "configs = []\n",
    "\n",
    "min_a100 = 1\n",
    "max_a100 = 70\n",
    "min_h100 = 1\n",
    "max_h100 = 40\n",
    "\n",
    "for num_a100 in range(min_a100, 2*max_a100, 1):\n",
    "    configs.append(baseline_a100_config(num_a100))\n",
    "\n",
    "for num_h100 in range(min_h100, 2*max_h100, 1):\n",
    "    configs.append(baseline_h100_config(num_h100))\n",
    "\n",
    "for num_prompts in range(min_a100, max_a100, 1):\n",
    "    for num_tokens in range(min_a100, max_a100, 1):\n",
    "        configs.append(splitwise_aa_config(num_prompts, num_tokens))\n",
    "\n",
    "for num_prompts in range(min_h100, max_h100, 1):\n",
    "    for num_tokens in range(min_h100, max_h100, 1):\n",
    "        configs.append(splitwise_hh_config(num_prompts, num_tokens))\n",
    "\n",
    "for num_prompts in range(min_h100, max_h100, 1):\n",
    "    for num_tokens in range(min_a100, max_a100, 1):\n",
    "        configs.append(splitwise_ha_config(num_prompts, num_tokens))\n",
    "\n",
    "for num_prompts in range(min_h100, max_h100, 1):\n",
    "    for num_tokens in range(min_h100, max_h100, 1):\n",
    "        configs.append(splitwise_hhcap_config(num_prompts, num_tokens))\n",
    "\n",
    "provision_code_trace = [\"rr_code_70_2min\"]\n",
    "#provision_conv_trace = [\"rr_conv_70_2min\"]\n",
    "\n",
    "provision_code_df, provision_code_request_dfs = get_data(configs, traces=provision_code_trace, seed=seed, model=model_to_plot)\n",
    "#provision_conv_df, provision_conv_request_dfs = get_data(configs, traces=provision_conv_trace, seed=seed, model=model_to_plot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_provision_sweep(result_df):\n",
    "    subset_df = result_df\n",
    "\n",
    "    # plot scatter of num_prompts vs num_tokens for the ttft times\n",
    "    fig, axs = plt.subplots(nrows=3, ncols=3, figsize=(9, 7), constrained_layout=True)\n",
    "\n",
    "    title_dict = {\n",
    "        \"ttft_slowdown\": \"TTFT Slowdown\",\n",
    "        \"tbt_slowdown\": \"TBT Slowdown\",\n",
    "        \"e2e_slowdown\": \"E2E Slowdown\"\n",
    "    }\n",
    "\n",
    "    y_vars = [\"ttft_slowdown\", \"tbt_slowdown\", \"e2e_slowdown\"]\n",
    "    quantiles = [0.5, 0.9, 0.99]\n",
    "\n",
    "    cmap = plt.get_cmap('viridis_r')\n",
    "    colors = cmap(np.arange(cmap.N))\n",
    "\n",
    "    max_slowdown = max(subset_df[\"ttft_slowdown_p99\"].max(), subset_df[\"tbt_slowdown_p99\"].max(), subset_df[\"e2e_slowdown_p99\"].max())\n",
    "    max_slo = 6\n",
    "    colors[-1] = [0, 0, 0, 1]  # RGBA for black\n",
    "    new_cmap = mcolors.ListedColormap(colors)\n",
    "\n",
    "    all_slo_df = subset_df\n",
    "    for y_var in y_vars:\n",
    "        for quantile in quantiles:\n",
    "            all_slo_df = all_slo_df[all_slo_df[f\"{y_var}_p{int(quantile * 100)}\"] <= get_slo(y_var, quantile)]\n",
    "\n",
    "    for y_var in y_vars:\n",
    "        for quantile in quantiles:\n",
    "            sc = axs[y_vars.index(y_var)][quantiles.index(quantile)].scatter(\n",
    "                subset_df[\"num_prompts\"],\n",
    "                subset_df[\"num_tokens\"],\n",
    "                c=subset_df[f\"{y_var}_p{int(quantile * 100)}\"],\n",
    "                #norm=mcolors.LogNorm(vmin=1, vmax=max_slo),\n",
    "                norm=mcolors.Normalize(vmin=1, vmax=max_slo),\n",
    "                cmap=new_cmap\n",
    "                #cmap='viridis_r'\n",
    "            )\n",
    "            axs[y_vars.index(y_var)][quantiles.index(quantile)].set_xlabel(\"# Prompt Machines\")\n",
    "            axs[y_vars.index(y_var)][quantiles.index(quantile)].set_ylabel(\"# Token Machines\")\n",
    "            axs[y_vars.index(y_var)][quantiles.index(quantile)].set_title(f\"p{int(quantile * 100)} {title_dict[y_var]}\")\n",
    "            #axs[y_vars.index(y_var)][quantiles.index(quantile)].legend(bbox_to_anchor=(0.5, 1.11), loc=\"lower center\", ncol=3, fontsize=7)\n",
    "            axs[y_vars.index(y_var)][quantiles.index(quantile)].grid()\n",
    "            \n",
    "            slo = get_slo(y_var, quantile)\n",
    "            # Filter the DataFrame to only include rows that meet the SLO\n",
    "            slo_df = subset_df[subset_df[f\"{y_var}_p{int(quantile * 100)}\"] <= slo]\n",
    "\n",
    "            # Group by 'num_prompts' and find the minimum 'num_tokens' for each group\n",
    "            frontier_df = slo_df.groupby('num_prompts')['num_tokens'].min().reset_index()\n",
    "\n",
    "            # Plot the frontier points\n",
    "            axs[y_vars.index(y_var)][quantiles.index(quantile)].scatter(\n",
    "                frontier_df[\"num_prompts\"],\n",
    "                frontier_df[\"num_tokens\"],\n",
    "                c='red',  # Color of the frontier points\n",
    "                label='SLO Frontier'\n",
    "            )\n",
    "\n",
    "            # Find the cost optimal and power optimal points that meet the SLO\n",
    "            #cost_optimal_point = slo_df.loc[slo_df['cost'].idxmin()]\n",
    "            #power_optimal_point = slo_df.loc[slo_df['power'].idxmin()]\n",
    "            cost_optimal_point = all_slo_df.loc[all_slo_df['cost'].idxmin()]\n",
    "            power_optimal_point = all_slo_df.loc[all_slo_df['power'].idxmin()]\n",
    "\n",
    "            # Plot the cost optimal point\n",
    "            axs[y_vars.index(y_var)][quantiles.index(quantile)].scatter(\n",
    "                cost_optimal_point[\"num_prompts\"],\n",
    "                cost_optimal_point[\"num_tokens\"],\n",
    "                c='azure',  # Color of the cost optimal point\n",
    "                s=120,\n",
    "                label='Cost Optimal',\n",
    "                marker='*',\n",
    "                edgecolors='black',\n",
    "            )\n",
    "\n",
    "            # Plot the power optimal point\n",
    "            #axs[y_vars.index(y_var)][quantiles.index(quantile)].scatter(\n",
    "            #    power_optimal_point[\"num_prompts\"],\n",
    "            #    power_optimal_point[\"num_tokens\"],\n",
    "            #    c='green',  # Color of the power optimal point\n",
    "            #    label='Power Optimal'\n",
    "            #)\n",
    "\n",
    "            #axs[y_vars.index(y_var)][quantiles.index(quantile)].legend()\n",
    "\n",
    "            # add colorbar\n",
    "            #plt.colorbar(sc, ax=axs[y_vars.index(y_var)][quantiles.index(quantile)])\n",
    "            # add colorbar with custom tick labels\n",
    "            cbar = plt.colorbar(sc, ax=axs[y_vars.index(y_var)][quantiles.index(quantile)])\n",
    "            tick_locs = list(cbar.get_ticks())\n",
    "            #tick_locs.append(slo)\n",
    "            cbar.set_ticks(tick_locs)\n",
    "            tick_labels = [str(int(tick)) if tick < max_slo else f'{max_slo}+' for tick in tick_locs]\n",
    "            #tick_labels[-1] = 'SLO'\n",
    "            cbar.set_ticklabels(tick_labels)\n",
    "            cbar.ax.axhline(get_slo(y_var, quantile), color='red', linewidth=3)\n",
    "\n",
    "            # Add SLO label to the left of the colorbar\n",
    "            cbar.set_label('SLO', rotation=0, labelpad=0, color='red')\n",
    "            slo_position = (slo - 1) / (max_slo - 1)\n",
    "            cbar.ax.yaxis.set_label_coords(-1.7, slo_position + 0.05)\n",
    "    print(cost_optimal_point[\"num_prompts\"], cost_optimal_point[\"num_tokens\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_provision_sweep(provision_code_df[provision_code_df[\"system\"] == \"Splitwise-HH\"])\n",
    "plt.savefig(f\"{plots_dir}/hh_provision_code_sweep_{model_to_plot}.pdf\", bbox_inches='tight')\n",
    "plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "provision_code_df.to_csv(f\"{plotsdata_dir}/provision_code_sweep_{model_to_plot}.csv\", index=False)\n",
    "provision_conv_df.to_csv(f\"{plotsdata_dir}/provision_conv_sweep_{model_to_plot}.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "isothroughput_code_cost_df = plot_isothroughput_cost_optimal_within_slo(provision_code_df, \"Baseline-A100\", slos)\n",
    "isothroughput_code_cost_df.to_csv(f\"{plotsdata_dir}/isothroughput_code_cost_{model_to_plot}.csv\", index=False)\n",
    "plt.savefig(f\"{plots_dir}/isothroughput_code_cost_{model_to_plot}.pdf\", bbox_inches='tight')\n",
    "plt.show()\n",
    "plt.close()\n",
    "\n",
    "isothroughput_code_power_df = plot_isothroughput_power_optimal_within_slo(provision_code_df, \"Baseline-A100\", slos)\n",
    "isothroughput_code_power_df.to_csv(f\"{plotsdata_dir}/isothroughput_code_power_{model_to_plot}.csv\", index=False)\n",
    "plt.savefig(f\"{plots_dir}/isothroughput_code_power_{model_to_plot}.pdf\", bbox_inches='tight')\n",
    "plt.show()\n",
    "plt.close()\n",
    "\n",
    "isothroughout_code_count_df = plot_isothroughput_count_optimal_within_slo(provision_code_df, \"Baseline-A100\", slos)\n",
    "isothroughout_code_count_df.to_csv(f\"{plotsdata_dir}/isothroughput_code_count_{model_to_plot}.csv\", index=False)\n",
    "plt.savefig(f\"{plots_dir}/isothroughput_code_count_{model_to_plot}.pdf\", bbox_inches='tight')\n",
    "plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "isothroughput_conv_cost_df = plot_isothroughput_cost_optimal_within_slo(provision_conv_df, \"Baseline-A100\", slos)\n",
    "isothroughput_conv_cost_df.to_csv(f\"{plotsdata_dir}/isothroughput_conv_cost_{model_to_plot}.csv\")\n",
    "plt.savefig(f\"{plots_dir}/isothroughput_conv_cost_{model_to_plot}.pdf\", bbox_inches='tight')\n",
    "plt.show()\n",
    "plt.close()\n",
    "\n",
    "isothroughput_conv_power_df = plot_isothroughput_power_optimal_within_slo(provision_conv_df, \"Baseline-A100\", slos)\n",
    "isothroughput_conv_power_df.to_csv(f\"{plotsdata_dir}/isothroughput_conv_power_{model_to_plot}.csv\")\n",
    "plt.savefig(f\"{plots_dir}/isothroughput_conv_power_{model_to_plot}.pdf\", bbox_inches='tight')\n",
    "plt.show()\n",
    "plt.close()\n",
    "\n",
    "isothroughput_conv_count_df = plot_isothroughput_count_optimal_within_slo(provision_conv_df, \"Baseline-A100\", slos)\n",
    "isothroughput_conv_count_df.to_csv(f\"{plotsdata_dir}/isothroughput_conv_count_{model_to_plot}.csv\")\n",
    "plt.savefig(f\"{plots_dir}/isothroughput_conv_count_{model_to_plot}.pdf\", bbox_inches='tight')\n",
    "plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "find_least_count(find_within_slo(provision_conv_df, slos)).drop_duplicates(subset=[\"system\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "find_least_power(find_within_slo(provision_code_df, slos))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_throughput(request_nodes_df, t_start=60, t_end=540):\n",
    "    \"\"\"\n",
    "    Finds the throughput of a request_df between t_start and t_end\n",
    "    \"\"\"\n",
    "    return request_nodes_df[\n",
    "            (request_nodes_df[\"node_type\"] == \"TOKEN\") & \\\n",
    "            (request_nodes_df[\"completion_timestamp\"] >= t_start) & \\\n",
    "            (request_nodes_df[\"completion_timestamp\"] < t_end)][\"request_id\"].nunique() / (t_end - t_start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for config in isocost_conv_configs:\n",
    "    request_nodes_df = get_request_nodes_with_config(results_dir, config, \"rr_conv_180\", seed=0, model=model_to_plot)\n",
    "    throughput = find_throughput(request_nodes_df)\n",
    "    print(f\"{config['name']}: {throughput} rps, ${round(config['cost'], 2)}, {round(throughput/config['cost'], 2)} rps/$\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "configs_within_slo = find_within_slo(provision_code_df, slos)\n",
    "cheapest_configs = find_cheapest(configs_within_slo)\n",
    "least_power_configs = find_least_power(configs_within_slo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_num_batch_tokens(config, trace, seed, model=\"\"):\n",
    "    df = get_instances_data_with_config(results_dir, config, trace, seed, model)\n",
    "    if \"splitwise\" in config.get(\"start_state\", \"\"):\n",
    "        num_prompt_batch_tokens, num_token_batch_tokens = get_num_batch_tokens_splitwise(df)\n",
    "        sns.ecdfplot(num_prompt_batch_tokens, label=\"Prompt\")\n",
    "        sns.ecdfplot(num_token_batch_tokens, label=\"Token\")\n",
    "    else:\n",
    "        num_batch_tokens = get_num_batch_tokens(df)\n",
    "        sns.ecdfplot(num_batch_tokens, label=\"Batch\")\n",
    "    plt.xlabel(\"Number of Batch Tokens\")\n",
    "    plt.ylabel(\"CDF\")\n",
    "    plt.legend()\n",
    "    plt.title(f'{config[\"name\"]} {config[\"scheduler\"]}, {trace}')\n",
    "    plt.grid()\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_duration_ccdf_batch_tokens(config, trace, seed, model=\"\"):\n",
    "    df = get_instances_data_with_config(results_dir, config, trace, seed, model)\n",
    "    grouped_df = df[[\"batch_tokens\", \"duration\"]].groupby(\"batch_tokens\").sum()\n",
    "\n",
    "    # find idle durations between iteration_end and iteration_start of next row in df for each instance identified by name\n",
    "    total_idle_duration = 0\n",
    "    for name in df[\"name\"].unique():\n",
    "        inst_df = df[df[\"name\"] == name].sort_values(\"iteration_start\")\n",
    "        inst_df[\"idle_duration\"] = inst_df[\"iteration_start\"] - inst_df[\"iteration_end\"].shift(1)\n",
    "        inst_df[\"idle_duration\"] = inst_df[\"idle_duration\"].fillna(0)\n",
    "        total_idle_duration += inst_df[\"idle_duration\"].sum()\n",
    "\n",
    "    # add entry to grouped_df at index 0\n",
    "    grouped_df.loc[0] = [total_idle_duration]\n",
    "\n",
    "    # sortby grouped_df.index\n",
    "    grouped_df = grouped_df.sort_index()\n",
    "    grouped_df[\"cum_duration\"] = np.cumsum(grouped_df[\"duration\"])\n",
    "    grouped_df[\"cum_duration\"] /= grouped_df[\"cum_duration\"].max()\n",
    "    # plot cumulative cdf of duration vs number of batch tokens\n",
    "    #plt.plot(grouped_df.index, np.cumsum(grouped_df[\"duration\"]))\n",
    "    plt.plot(grouped_df.index, grouped_df[\"cum_duration\"])\n",
    "    plt.xlabel(\"Number of Batch Tokens\")\n",
    "    plt.ylabel(\"Cumulative Duration (s)\")\n",
    "    plt.grid()\n",
    "    plt.title(f'{config[\"name\"]} {config[\"scheduler\"]}, {trace}')\n",
    "\n",
    "    #if \"splitwise\" in config.get(\"start_state\", \"\"):\n",
    "    #    n_prompt = int(config[\"start_state\"].split(\"_\")[1])\n",
    "    #    num_prompt_batch_tokens, num_token_batch_tokens = get_num_batch_tokens_splitwise(df, n_prompt)\n",
    "    #    sns.ecdfplot(num_prompt_batch_tokens, label=\"Prompt\")\n",
    "    #    sns.ecdfplot(num_token_batch_tokens, label=\"Token\")\n",
    "    #else:\n",
    "    #    num_batch_tokens = get_num_batch_tokens(df)\n",
    "    #    sns.ecdfplot(num_batch_tokens, label=\"Batch\")\n",
    "    #plt.xlabel(\"Number of Batch Tokens\")\n",
    "    #plt.ylabel(\"CDF\")\n",
    "    #plt.legend()\n",
    "    #plt.grid()\n",
    "    #return df   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_idle_duration(df):\n",
    "    total_idle_duration = 0\n",
    "    for name in df[\"name\"].unique():\n",
    "        inst_df = df[df[\"name\"] == name].sort_values(\"iteration_start\")\n",
    "        inst_df[\"idle_duration\"] = inst_df[\"iteration_start\"] - inst_df[\"iteration_end\"].shift(1)\n",
    "        inst_df[\"idle_duration\"] = inst_df[\"idle_duration\"].fillna(0)\n",
    "        total_idle_duration += inst_df[\"idle_duration\"].sum()\n",
    "    return total_idle_duration\n",
    "\n",
    "def compare_duration_ccdf_batch_tokens(baseline_config, splitwise_config, trace, seed, model=\"\"):\n",
    "    baseline_df = get_instances_data_with_config(results_dir, baseline_config, trace, seed, model)\n",
    "    splitwise_df = get_instances_data_with_config(results_dir, splitwise_config, trace, seed, model)\n",
    "\n",
    "    # for baseline\n",
    "    # find idle durations between iteration_end and iteration_start of next row in df for each instance identified by name\n",
    "    baseline_idle_duration = find_idle_duration(baseline_df)\n",
    "    # add entry to grouped df at index 0\n",
    "    grouped_baseline_df = baseline_df[[\"batch_tokens\", \"duration\"]].groupby(\"batch_tokens\").sum()\n",
    "    grouped_baseline_df.loc[0] = [baseline_idle_duration]\n",
    "\n",
    "    # for splitwise, separate into prompt and token servers, and repeat the same process\n",
    "    # find idle durations between iteration_end and iteration_start of next row in df for each instance identified by name\n",
    "    splitwise_prompt_df = splitwise_df[splitwise_df[\"tag\"] == \"prompt\"]\n",
    "    splitwise_token_df = splitwise_df[splitwise_df[\"tag\"] == \"token\"]\n",
    "    splitwise_prompt_idle_duration = find_idle_duration(splitwise_prompt_df)\n",
    "    splitwise_token_idle_duration = find_idle_duration(splitwise_token_df)\n",
    "    # add entry to grouped df at index 0\n",
    "    grouped_splitwise_prompt_df = splitwise_prompt_df[[\"batch_tokens\", \"duration\"]].groupby(\"batch_tokens\").sum()\n",
    "    grouped_splitwise_prompt_df.loc[0] = [splitwise_prompt_idle_duration]\n",
    "    grouped_splitwise_token_df = splitwise_token_df[[\"batch_tokens\", \"duration\"]].groupby(\"batch_tokens\").sum()\n",
    "    grouped_splitwise_token_df.loc[0] = [splitwise_token_idle_duration]\n",
    "\n",
    "    # sortby grouped_df.index\n",
    "    grouped_baseline_df = grouped_baseline_df.sort_index()\n",
    "    grouped_baseline_df[\"cum_duration\"] = np.cumsum(grouped_baseline_df[\"duration\"])\n",
    "    grouped_baseline_df[\"cum_duration\"] /= grouped_baseline_df[\"cum_duration\"].max()\n",
    "\n",
    "    grouped_splitwise_prompt_df = grouped_splitwise_prompt_df.sort_index()\n",
    "    grouped_splitwise_prompt_df[\"cum_duration\"] = np.cumsum(grouped_splitwise_prompt_df[\"duration\"])\n",
    "    grouped_splitwise_prompt_df[\"cum_duration\"] /= grouped_splitwise_prompt_df[\"cum_duration\"].max()\n",
    "    \n",
    "    grouped_splitwise_token_df = grouped_splitwise_token_df.sort_index()\n",
    "    grouped_splitwise_token_df[\"cum_duration\"] = np.cumsum(grouped_splitwise_token_df[\"duration\"])\n",
    "    grouped_splitwise_token_df[\"cum_duration\"] /= grouped_splitwise_token_df[\"cum_duration\"].max()\n",
    "\n",
    "    fig, axs = plt.subplots(1, 1, figsize=(3, 3), constrained_layout=True)\n",
    "\n",
    "    # plot cumulative cdf of duration vs number of batch tokens\n",
    "    #plt.plot(grouped_df.index, np.cumsum(grouped_df[\"duration\"]))\n",
    "    axs.plot(grouped_baseline_df.index, grouped_baseline_df[\"cum_duration\"], label=\"Baseline-H100\")\n",
    "    axs.plot(grouped_splitwise_prompt_df.index, grouped_splitwise_prompt_df[\"cum_duration\"], label=\"Splitwise-HH (Prompt)\")\n",
    "    axs.plot(grouped_splitwise_token_df.index, grouped_splitwise_token_df[\"cum_duration\"], label=\"Splitwise-HH (Token)\")\n",
    "\n",
    "    axs.set_xlabel(\"Number of Batch Tokens\")\n",
    "    axs.set_ylabel(\"Cumulative Duration\")\n",
    "    axs.grid()\n",
    "    axs.set_xscale(\"log\")\n",
    "    axs.legend(loc=\"lower center\", ncol=1, bbox_to_anchor=(0.5, 1.0))\n",
    "    #ax.title(f'{config[\"name\"]} {config[\"scheduler\"]}, {trace}')\n",
    "    \n",
    "    # return dataframe\n",
    "    return baseline_df, splitwise_df\n",
    "\n",
    "    #if \"splitwise\" in config.get(\"start_state\", \"\"):\n",
    "    #    n_prompt = int(config[\"start_state\"].split(\"_\")[1])\n",
    "    #    num_prompt_batch_tokens, num_token_batch_tokens = get_num_batch_tokens_splitwise(df, n_prompt)\n",
    "    #    sns.ecdfplot(num_prompt_batch_tokens, label=\"Prompt\")\n",
    "    #    sns.ecdfplot(num_token_batch_tokens, label=\"Token\")\n",
    "    #else:\n",
    "    #    num_batch_tokens = get_num_batch_tokens(df)\n",
    "    #    sns.ecdfplot(num_batch_tokens, label=\"Batch\")\n",
    "    #plt.xlabel(\"Number of Batch Tokens\")\n",
    "    #plt.ylabel(\"CDF\")\n",
    "    #plt.legend()\n",
    "    #plt.grid()\n",
    "    #return df   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline_df, splitwise_df = compare_duration_ccdf_batch_tokens(\n",
    "    baseline_h100_config(40),\n",
    "    splitwise_hh_config(25, 15),\n",
    "    #\"rr_conv_70\",\n",
    "    \"rr_conv_130\",\n",
    "    seed=0,\n",
    "    model=model_to_plot)\n",
    "baseline_df.to_csv(os.path.join(plotsdata_dir, f\"duration_ccdf_batch_tokens_baseline_{model_to_plot}_conv130.csv\"))\n",
    "splitwise_df.to_csv(os.path.join(plotsdata_dir, f\"duration_ccdf_batch_tokens_splitwise_{model_to_plot}_conv130.csv\"))\n",
    "#plt.savefig(os.path.join(plots_dir, f\"duration_ccdf_batch_tokens_{model_to_plot}_conv70.pdf\"))\n",
    "plt.savefig(os.path.join(plots_dir, f\"duration_ccdf_batch_tokens_{model_to_plot}_conv130.pdf\"))\n",
    "plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_sweep(results_df, title=None, x=\"num_prompts\"):\n",
    "    fig, axs = plt.subplots(nrows=3, ncols=2, figsize=(6, 4), sharex=True, constrained_layout=True)\n",
    "    sns.lineplot(data=results_df, x=x, y=\"ttft_slowdown_p90\", style=\"system\", markers=True, markersize=7, ax=axs[0][0])\n",
    "    sns.lineplot(data=results_df, x=x, y=\"tbt_slowdown_p90\", style=\"system\", markers=True, markersize=7, ax=axs[1][0])\n",
    "    sns.lineplot(data=results_df, x=x, y=\"e2e_slowdown_p90\", style=\"system\", markers=True, markersize=7, ax=axs[2][0])\n",
    "    sns.lineplot(data=results_df, x=x, y=\"ttft_slowdown_p50\", style=\"system\", markers=True, markersize=7, ax=axs[0][1])\n",
    "    sns.lineplot(data=results_df, x=x, y=\"tbt_slowdown_p50\", style=\"system\", markers=True, markersize=7, ax=axs[1][1])\n",
    "    sns.lineplot(data=results_df, x=x, y=\"e2e_slowdown_p50\", style=\"system\", markers=True, markersize=7, ax=axs[2][1])\n",
    "\n",
    "    for ax in axs.flatten():\n",
    "        ax.grid()\n",
    "        ax.set_xlabel(f\"{x} servers\")\n",
    "\n",
    "    #sns.move_legend(axs[0][0], \"lower center\", bbox_to_anchor=(0.5, 1.05), ncol=2, title=\"\")\n",
    "    axs[0][0].get_legend().set_visible(False)\n",
    "    axs[1][0].get_legend().set_visible(False)\n",
    "    axs[2][0].get_legend().set_visible(False)\n",
    "    axs[0][1].get_legend().set_visible(False)\n",
    "    axs[1][1].get_legend().set_visible(False)\n",
    "    axs[2][1].get_legend().set_visible(False)\n",
    "\n",
    "    # create a single legend in center of figure\n",
    "    handles, labels = axs[0][0].get_legend_handles_labels()\n",
    "    fig.legend(handles, labels, loc='lower center', ncol=3, title=\"\", bbox_to_anchor=(0.5, 1.01))\n",
    "\n",
    "    #axs[0][0].set_yscale(\"log\")\n",
    "    #axs[0][1].set_yscale(\"log\")\n",
    "    #axs[2][0].set_yscale(\"log\")\n",
    "    #axs[2][1].set_yscale(\"log\")\n",
    "    #axs[0][0].set_ylim(bottom=0, top=2)\n",
    "    #axs[0][1].set_ylim(bottom=0, top=2)\n",
    "\n",
    "    # set same y axis limits for plots in the same row (same as 0th column)\n",
    "    #axs[0][1].set_ylim(axs[0][0].get_ylim())\n",
    "    #axs[1][1].set_ylim(axs[1][0].get_ylim())\n",
    "    #axs[2][1].set_ylim(axs[2][0].get_ylim())\n",
    "\n",
    "\n",
    "    axs[0][0].set_ylabel(\"p90 TTFT (s)\")\n",
    "    axs[1][0].set_ylabel(\"p90 TBT (s)\")\n",
    "    #axs[2][0].set_ylabel(\"p99 Nth Token (s)\")\n",
    "    axs[2][0].set_ylabel(\"p90 e2e (s)\")\n",
    "    axs[0][1].set_ylabel(\"p50 TTFT (s)\")\n",
    "    axs[1][1].set_ylabel(\"p50 TBT (s)\")\n",
    "    axs[2][1].set_ylabel(\"p50 e2e (s)\")\n",
    "    #axs[2][1].set_ylabel(\"p50 Nth Token (s)\")\n",
    "\n",
    "    if title:\n",
    "        fig.suptitle(title, fontsize=12)\n",
    "\n",
    "    # set 300dpi\n",
    "    plt.gcf().set_dpi(300)\n",
    "\n",
    "    plt.show()\n",
    "    plt.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# isopower sweeps\n",
    "\n",
    "configs = []\n",
    "\n",
    "max_h100 = 40\n",
    "for num_h100 in range(5, max_h100, 5):\n",
    "    #num_a100 = int(10200 * (max_h100 - num_h100) // 6500)\n",
    "    num_a100 = int(44 * (max_h100 - num_h100) // 24.8)\n",
    "    configs.append(splitwise_ha_config(num_h100, num_a100))\n",
    "\n",
    "for num_h100 in range(5, max_h100, 5):\n",
    "    num_prompts = num_h100\n",
    "    num_tokens = max_h100 - num_prompts\n",
    "    configs.append(splitwise_hh_config(num_prompts, num_tokens))\n",
    "    configs.append(splitwise_hhcap_config(num_prompts, num_tokens))\n",
    "\n",
    "max_a100 = 70\n",
    "for num_prompts in range(5, max_a100, 5):\n",
    "    num_tokens = max_a100 - num_prompts\n",
    "    configs.append(splitwise_aa_config(num_prompts, num_tokens))\n",
    "\n",
    "#traces = [\"rr_conv_70\"]\n",
    "traces = [\"rr_code_100\"]\n",
    "\n",
    "results_df, request_dfs = get_data(configs, traces, seed=seed, model=model_to_plot)\n",
    "plot_sweep(results_df, title=f\"Isopower sweeps, {traces[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# isocost sweeps\n",
    "\n",
    "configs = []\n",
    "\n",
    "max_h100 = 40\n",
    "for num_h100 in range(5, max_h100, 5):\n",
    "    #num_a100 = int(10200 * (max_h100 - num_h100) // 6500)\n",
    "    num_a100 = int(4.76 * (max_h100 - num_h100) // 2.21)\n",
    "    configs.append(splitwise_ha_config(num_h100, num_a100))\n",
    "\n",
    "for num_h100 in range(5, max_h100, 5):\n",
    "    num_prompts = num_h100\n",
    "    num_tokens = max_h100 - num_prompts\n",
    "    configs.append(splitwise_hh_config(num_prompts, num_tokens))\n",
    "\n",
    "max_a100 = 86\n",
    "for num_tokens in range(5, max_a100, 5):\n",
    "    num_prompts = max_a100 - num_tokens\n",
    "    configs.append(splitwise_aa_config(num_prompts, num_tokens))\n",
    "\n",
    "#traces = [\"rr_conv_70\"]\n",
    "traces = [\"rr_code_90\"]\n",
    "\n",
    "results_df, request_dfs = get_data(configs, traces, seed=seed, model=model_to_plot)\n",
    "plot_sweep(results_df, title=f\"Isocost sweeps, {traces[0]}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sim",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
